{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from daal.data_management import AOSNumericTable\n",
    "from daal.data_management import SOANumericTable\n",
    "from daal.data_management import BlockDescriptor_Intc\n",
    "from daal.data_management import BlockDescriptor\n",
    "from daal.data_management import BlockDescriptor_Float64\n",
    "from daal.data_management import readOnly\n",
    "from daal.data_management import readWrite\n",
    "from daal.data_management import data_feature_utils\n",
    "from daal.data_management import HomogenNumericTable\n",
    "from daal.data_management import NumericTableIface\n",
    "from daal.data_management import MergedNumericTable\n",
    "from daal.data_management import FileDataSource\n",
    "from daal.data_management import StringDataSource\n",
    "from daal.data_management import DataSourceIface\n",
    "from daal.data_management import packed_mask\n",
    "\n",
    "from daal.algorithms import kmeans \n",
    "from daal.algorithms.kmeans import (\n",
    "    Batch_Float64LloydDense, init, data as d, inputCentroids, assignments, centroids, goalFunction\n",
    ")\n",
    "\n",
    "from daal.algorithms.linear_regression import training\n",
    "from daal.algorithms.linear_regression import prediction\n",
    "\n",
    "import daal.algorithms.normalization.zscore as zscore\n",
    "\n",
    "from daal import step1Local\n",
    "from daal import step2Master\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def printNumericTable(data_table, message='', num_printed_rows=0, num_printed_cols=0,\n",
    "                      interval=10):\n",
    "    num_rows = data_table.getNumberOfRows()\n",
    "    num_cols = data_table.getNumberOfColumns()\n",
    "    layout = data_table.getDataLayout()\n",
    "\n",
    "    if num_printed_rows != 0:\n",
    "        num_printed_rows = min(num_rows, num_printed_rows)\n",
    "    else:\n",
    "        num_printed_rows = num_rows\n",
    "\n",
    "    if num_printed_cols != 0:\n",
    "        num_printed_cols = min(num_cols, num_printed_cols)\n",
    "    else:\n",
    "        num_printed_cols = num_cols\n",
    "\n",
    "    block = BlockDescriptor()\n",
    "    if isFull(layout) or layout == NumericTableIface.csrArray:\n",
    "        data_table.getBlockOfRows(0, num_rows, readOnly, block)\n",
    "        printArray(block.getArray(), num_printed_cols, num_printed_rows,\n",
    "                   num_cols, message, interval)\n",
    "        data_table.releaseBlockOfRows(block)\n",
    "    else:\n",
    "        packed_table = data_table.getBlockOfRowsAsDouble(0, num_rows)\n",
    "        if isLower(layout):\n",
    "            printLowerArray(packed_table, num_printed_rows, message, interval)\n",
    "        elif isUpper(layout):\n",
    "            printUpperArray(packed_table, num_printed_cols, num_printed_rows,\n",
    "                            num_cols, message, interval)\n",
    "        \n",
    "def isFull(layout):\n",
    "    layout_int = int(layout)\n",
    "    if packed_mask & layout_int:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def printArray(array, num_printed_cols, num_printed_rows, num_cols, message,\n",
    "               interval=10, flt64=True):\n",
    "    print(message)\n",
    "    flat_array = array.flatten()\n",
    "    decimals = '3' if flt64 else '0'\n",
    "    for i in range(num_printed_rows):\n",
    "        for j in range(num_printed_cols):\n",
    "            print(\"{:<{width}.{dec}f}\".format(\n",
    "                flat_array[i * num_cols + j], width=interval, dec=decimals), end=''\n",
    "            )\n",
    "        print()\n",
    "    print()\n",
    "\n",
    "    \n",
    "    \n",
    "def getNPArray(data_table):\n",
    "    num_rows = data_table.getNumberOfRows()\n",
    "    block = BlockDescriptor()\n",
    "    data_table.getBlockOfRows(0, num_rows, readOnly, block)\n",
    "    np_array = block.getArray()\n",
    "    data_table.releaseBlockOfRows(block)\n",
    "    return np_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Loading Data from a NumPy Array (AOS)\n",
    "\n",
    "* Loading from a NumPy Array:\n",
    "* Has to be a Structured NumPy Array!\n",
    "    * `dtype` not none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "points = np.array([(0.5, -1.3, 1, 100.1),\n",
    "                   (2.5, -3.3, 2, 200.2),\n",
    "                   (4.5, -5.3, 2, 350.3),\n",
    "                   (6.5, -7.3, 0, 470.4),\n",
    "                   (8.5, -9.3, 1, 270.5)],\n",
    "                  dtype=[('x','f4'), ('y','f4'), \n",
    "                         ('categ','i4'), ('value','f8')])  \n",
    "\n",
    "\n",
    "dataTable = AOSNumericTable(points)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Retrieving values of a Feature\n",
    "* By Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.5]\n",
      " [ 6.5]\n",
      " [ 8.5]]\n"
     ]
    }
   ],
   "source": [
    "nObservations = len(points)\n",
    "firstReadRow = 2\n",
    "readFeatureIdx = 0\n",
    "\n",
    "floatBlock = BlockDescriptor_Float64()\n",
    "dataTable.getBlockOfColumnValues(readFeatureIdx, firstReadRow,\n",
    "                                 nObservations, readOnly, floatBlock)\n",
    "dataTable.releaseBlockOfColumnValues(floatBlock)\n",
    "print(floatBlock.getArray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Retrieving observations\n",
    "* By Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block of Rows:\n",
      "[[   4.5          -5.30000019    2.          350.3       ]\n",
      " [   6.5          -7.30000019    0.          470.4       ]\n",
      " [   8.5          -9.30000019    1.          270.5       ]]\n"
     ]
    }
   ],
   "source": [
    "firstReadRow = 2\n",
    "nRead = 3\n",
    "doubleBlock = BlockDescriptor_Float64()\n",
    "dataTable.getBlockOfRows(firstReadRow, nRead, readOnly, doubleBlock)\n",
    "\n",
    "print(\"Block of Rows:\")\n",
    "print(doubleBlock.getArray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Loading Data from a NumPy Array (SOA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def toString(v):\n",
    "    if v == data_feature_utils.DAAL_CATEGORICAL:\n",
    "        return \"DAAL_CATEGORICAL\"\n",
    "    elif v == data_feature_utils.DAAL_ORDINAL:\n",
    "        return \"DAAL_ORDINAL\"\n",
    "    elif v == data_feature_utils.DAAL_CONTINUOUS:\n",
    "        return \"DAAL_CONTINUOUS\"\n",
    "    else:\n",
    "        return \"[Unknown FeatureType]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nObservations = 10\n",
    "nFeatures = 4\n",
    "\n",
    "dDataSOA = np.array([1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2, 2.4, 2.6, 2.8], dtype=np.float64)\n",
    "fDataSOA = np.array([3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0], dtype=np.float32)\n",
    "iDataSOA = np.array([-10, -20, -30, -40, -50, -60, -70, -80, -90, -100], dtype=np.int32)\n",
    "cDataSOA = np.array([1, 2, 3, 4, 5, 1, 2, 3, 4, 5], dtype=np.uint8)\n",
    "\n",
    "dataTable = SOANumericTable(nFeatures, nObservations)\n",
    "dataTable.setArray(cDataSOA, 0)\n",
    "dataTable.setArray(fDataSOA, 1)\n",
    "dataTable.setArray(dDataSOA, 2)\n",
    "dataTable.setArray(iDataSOA, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Setting and Retrieving data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Setting datatypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dict = dataTable.getDictionary()\n",
    "dict[0].featureType = data_feature_utils.DAAL_CONTINUOUS\n",
    "dict[1].featureType = data_feature_utils.DAAL_CONTINUOUS\n",
    "dict[2].featureType = data_feature_utils.DAAL_CONTINUOUS\n",
    "dict[3].featureType = data_feature_utils.DAAL_CATEGORICAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Retrieving datatypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataTypes:\n",
      "0: DAAL_CONTINUOUS, 1: DAAL_CONTINUOUS, 2: DAAL_CONTINUOUS, 3: DAAL_CATEGORICAL, "
     ]
    }
   ],
   "source": [
    "pDictionary = dataTable.getDictionary()\n",
    "print(\"\\nDataTypes:\")\n",
    "for i in range(0, nFeatures):\n",
    "    featureType = pDictionary[i].featureType\n",
    "    print(\"{}: {}\".format(i, toString(featureType)), end=', ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Merging data\n",
    "\n",
    "* `MergedNumericTable`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.000     0.100     0.200     0.300     0.400     0.500     0.600     0.700     0.800     0.900     1.000     \n",
      "1.000     1.100     1.200     1.300     1.400     1.500     1.600     1.700     1.800     1.900     2.000     \n",
      "2.000     2.100     2.200     2.300     2.400     2.500     2.600     2.700     2.800     2.900     3.000     \n",
      "3.000     3.100     3.200     3.300     3.400     3.500     3.600     3.700     3.800     3.900     4.000     \n",
      "4.000     4.100     4.200     4.300     4.400     4.500     4.600     4.700     4.800     4.900     5.000     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1 = np.array([[0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "                  [1.0, 1.1, 1.2, 1.3, 1.4],\n",
    "                  [2.0, 2.1, 2.2, 2.3, 2.4],\n",
    "                  [3.0, 3.1, 3.2, 3.3, 3.4],\n",
    "                  [4.0, 4.1, 4.2, 4.3, 4.4],])\n",
    "\n",
    "data2 = np.array([(0.5, 0.6, 0.7, 0.8, 0.9, 1),\n",
    "                  (1.5, 1.6, 1.7, 1.8, 1.9, 2),\n",
    "                  (2.5, 2.6, 2.7, 2.8, 2.9, 3),\n",
    "                  (3.5, 3.6, 3.7, 3.8, 3.9, 4),\n",
    "                  (4.5, 4.6, 4.7, 4.8, 4.9, 5),])\n",
    "\n",
    "\n",
    "dataTable1 = HomogenNumericTable(data1)\n",
    "dataTable2 = HomogenNumericTable(data2)\n",
    "\n",
    "dataTable = MergedNumericTable()\n",
    "dataTable.addNumericTable(dataTable1)\n",
    "dataTable.addNumericTable(dataTable2)\n",
    "\n",
    "printNumericTable(dataTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Merging data\n",
    "\n",
    "* Modifying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.   3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9  4. ]\n",
      "[[ 10.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10.]]\n"
     ]
    }
   ],
   "source": [
    "nFeatures1 = 5\n",
    "nFeatures2 = 6\n",
    "firstReadRow = 3\n",
    "nRead = 1\n",
    "\n",
    "\n",
    "block = BlockDescriptor_Float64()\n",
    "dataTable.getBlockOfRows(firstReadRow, nRead, readWrite, block)\n",
    "print(block.getArray().flatten())\n",
    "\n",
    "selected_row = block.getArray()\n",
    "for i in range(0,len(selected_row[0])):\n",
    "    selected_row[0][i] = 10\n",
    "    \n",
    "print(block.getArray())\n",
    "dataTable.releaseBlockOfRows(block)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Merging data\n",
    "\n",
    "* Modifying data (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10.  10.  10.  10.  10.]]\n",
      "[[ 10.  10.  10.  10.  10.  10.]]\n"
     ]
    }
   ],
   "source": [
    "dataTable1.getBlockOfRows(firstReadRow, nRead, readOnly, block)\n",
    "print(block.getArray())\n",
    "dataTable1.releaseBlockOfRows(block)\n",
    "\n",
    "dataTable2.getBlockOfRows(firstReadRow, nRead, readOnly, block)\n",
    "print(block.getArray())\n",
    "dataTable2.releaseBlockOfRows(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Sampling\n",
    "\n",
    "* With or without Replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "110\n",
      "436\n",
      "110\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "data = np.genfromtxt('housing-full.csv', delimiter=',')\n",
    "sample = np.random.choice(len(data),size=math.floor(.8*len(data)),\n",
    "                          replace=False)\n",
    "\n",
    "select = np.in1d(range(data.shape[0]), sample)\n",
    "\n",
    "print(len(data[select,:]))\n",
    "print(len(data[~select,:]))\n",
    "\n",
    "train_data = HomogenNumericTable(data[select,:])\n",
    "test_data = HomogenNumericTable(data[~select,:])\n",
    "\n",
    "print(train_data.getNumberOfRows())\n",
    "print(test_data.getNumberOfRows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dataSource2 = FileDataSource('housing-full.csv',\n",
    "                            DataSourceIface.doAllocateNumericTable,\n",
    "                            DataSourceIface.doDictionaryFromContext)\n",
    "dataSource2.loadDataBlock()\n",
    "\n",
    "data2 = dataSource2.getNumericTable()\n",
    "\n",
    "\n",
    "# Create an algorithm\n",
    "algorithm = zscore.Batch(method=zscore.sumDense)\n",
    "\n",
    "# Set an input object for the algorithm\n",
    "algorithm.input.set(zscore.data, data2)\n",
    "\n",
    "# Compute Z-score normalization function\n",
    "res = algorithm.compute()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows of the input data:\n",
      "42000.000 5850.000  3.000     1.000     2.000     \n",
      "38500.000 4000.000  2.000     1.000     1.000     \n",
      "49500.000 3060.000  3.000     1.000     1.000     \n",
      "60500.000 6650.000  3.000     1.000     2.000     \n",
      "61000.000 6360.000  2.000     1.000     1.000     \n",
      "66000.000 4160.000  3.000     1.000     1.000     \n",
      "66000.000 3880.000  3.000     2.000     2.000     \n",
      "69000.000 4160.000  3.000     1.000     3.000     \n",
      "83800.000 4800.000  3.000     1.000     1.000     \n",
      "88500.000 5500.000  3.000     2.000     4.000     \n",
      "\n",
      "First 10 rows of the z-score normalization result:\n",
      "-0.978    0.323     0.047     -0.569    0.222     \n",
      "-1.109    -0.531    -1.309    -0.569    -0.930    \n",
      "-0.697    -0.964    0.047     -0.569    -0.930    \n",
      "-0.285    0.692     0.047     -0.569    0.222     \n",
      "-0.267    0.558     -1.309    -0.569    -0.930    \n",
      "-0.079    -0.457    0.047     -0.569    -0.930    \n",
      "-0.079    -0.586    0.047     1.422     0.222     \n",
      "0.033     -0.457    0.047     -0.569    1.373     \n",
      "0.587     -0.162    0.047     -0.569    -0.930    \n",
      "0.763     0.161     0.047     1.422     2.525     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "printNumericTable(data2, \"First 10 rows of the input data:\", 10)\n",
    "\n",
    "printNumericTable(res.get(zscore.normalizedData), \n",
    "                  \"First 10 rows of the z-score normalization result:\", 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reading from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations read: 435\n"
     ]
    }
   ],
   "source": [
    "nFeatures = 4\n",
    "nOutcomes = 1\n",
    "\n",
    "trainDatasetFileName = './housing-train.csv'\n",
    "\n",
    "trainDataSource = FileDataSource(trainDatasetFileName, \n",
    "                            DataSourceIface.notAllocateNumericTable,\n",
    "                            DataSourceIface.doDictionaryFromContext)\n",
    "\n",
    "trainData = HomogenNumericTable(nFeatures, 0, \n",
    "                                NumericTableIface.notAllocate)\n",
    "trainOutcome = HomogenNumericTable(nOutcomes, 0, \n",
    "                                   NumericTableIface.notAllocate)\n",
    "mergedData = MergedNumericTable(trainOutcome, trainData)\n",
    "nObservations = trainDataSource.loadDataBlock(mergedData)\n",
    "print(\"Observations read: {}\".format(nObservations))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from CSV files\n",
    "## The NumPy Way\n",
    "\n",
    "* Be careful with the data taken from a single column\n",
    "    * `HomogenNumericTable` can only be created from a unustructured **bi-dimensional** numpy array;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dependent variable: \n",
      "42000.000 \n",
      "38500.000 \n",
      "49500.000 \n",
      "60500.000 \n",
      "61000.000 \n",
      "66000.000 \n",
      "66000.000 \n",
      "69000.000 \n",
      "83800.000 \n",
      "88500.000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "housing_dataset = np.genfromtxt('housing-train.csv', delimiter=',')\n",
    "train_data = np.delete(housing_dataset, np.s_[0:1:1],1)\n",
    "\n",
    "train_data_table = HomogenNumericTable(train_data)\n",
    "\n",
    "# Create a bi-dimensional numpy array from the slice of the first column\n",
    "train_outcome = np.array([[item] for item in housing_dataset[:,0]])\n",
    "\n",
    "train_outcome_table = HomogenNumericTable(train_outcome)\n",
    "\n",
    "printNumericTable(train_outcome_table, \"The dependent variable: \", 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Training the Model\n",
    "## Using the DAAL read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression coefficients:\n",
      "-6356.393 6.127     2760.738  16551.026 7322.687  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "algorithm = training.Batch_Float64NormEqDense()\n",
    "                                                                                                   \n",
    "algorithm.input.set(training.data, trainData)\n",
    "algorithm.input.set(training.dependentVariables, trainOutcome)\n",
    "\n",
    "trainingResult = algorithm.compute()\n",
    "printNumericTable(trainingResult.get(training.model).getBeta(), \n",
    "                  \"Linear Regression coefficients:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "## Using the numpy read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression coefficients:\n",
      "-6356.393 6.127     2760.738  16551.026 7322.687  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "algorithm = training.Batch_Float64NormEqDense()\n",
    "                                                                                                   \n",
    "algorithm.input.set(training.data, train_data_table)\n",
    "\n",
    "algorithm.input.set(training.dependentVariables, train_outcome_table)\n",
    "\n",
    "\n",
    "trainingResult = algorithm.compute()\n",
    "printNumericTable(trainingResult.get(training.model).getBeta(), \n",
    "                  \"Linear Regression coefficients:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The quality of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.533399894442\n"
     ]
    }
   ],
   "source": [
    "algorithm = prediction.Batch()\n",
    "algorithm.input.setTable(prediction.data, trainData)\n",
    "algorithm.input.setModel(prediction.model, \n",
    "                         trainingResult.get(training.model))\n",
    "\n",
    "predictionResult = algorithm.compute()\n",
    "\n",
    "prediction_result = getNPArray(\n",
    "    predictionResult.get(prediction.prediction))\n",
    "real_values = getNPArray(trainOutcome)\n",
    "\n",
    "real_values_mean = np.sum(real_values)/len(real_values)\n",
    "ssreg = np.sum((prediction_result-real_values_mean)**2)\n",
    "sstot = np.sum((real_values - real_values_mean)**2)\n",
    "r_squared = ssreg / sstot\n",
    "\n",
    "print(r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Testing your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing points read: 111\n"
     ]
    }
   ],
   "source": [
    "testDatasetFileName = './housing-test.csv'\n",
    "\n",
    "testDataSource = FileDataSource(testDatasetFileName, \n",
    "                            DataSourceIface.notAllocateNumericTable,\n",
    "                            DataSourceIface.doDictionaryFromContext)\n",
    "\n",
    "testData = HomogenNumericTable(nFeatures, 0, \n",
    "                               NumericTableIface.notAllocate)\n",
    "\n",
    "testGroundTruth = HomogenNumericTable(nOutcomes, 0, \n",
    "                                      NumericTableIface.notAllocate)\n",
    "\n",
    "mergedData = MergedNumericTable(testGroundTruth,testData)\n",
    "\n",
    "nObservations = testDataSource.loadDataBlock(mergedData)\n",
    "\n",
    "print(\"Testing points read: {}\".format(nObservations))\n",
    "\n",
    "algorithm = prediction.Batch()\n",
    "\n",
    "algorithm.input.setTable(prediction.data, testData)\n",
    "algorithm.input.setModel(prediction.model, \n",
    "                         trainingResult.get(training.model))\n",
    "\n",
    "predictionResult = algorithm.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Testing your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression prediction results: (first 10 rows):\n",
      "77584.291 \n",
      "97463.689 \n",
      "54689.190 \n",
      "65962.833 \n",
      "75165.556 \n",
      "47366.503 \n",
      "55175.751 \n",
      "47366.503 \n",
      "62841.671 \n",
      "65407.807 \n",
      "\n",
      "Ground truth (first 10 rows):\n",
      "75000.000 \n",
      "132000.000\n",
      "60000.000 \n",
      "65000.000 \n",
      "69000.000 \n",
      "51900.000 \n",
      "57000.000 \n",
      "65000.000 \n",
      "79500.000 \n",
      "72500.000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "printNumericTable(predictionResult.get(prediction.prediction), \n",
    "          \"Linear Regression prediction results: (first 10 rows):\", 10)\n",
    "printNumericTable(testGroundTruth, \"Ground truth (first 10 rows):\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Testing your Model\n",
    "\n",
    "## Error Measures:\n",
    "\n",
    "### $R^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54\n"
     ]
    }
   ],
   "source": [
    "prediction_result = getNPArray(\n",
    "    predictionResult.get(prediction.prediction))\n",
    "real_values = getNPArray(testGroundTruth)\n",
    "\n",
    "training_data_outcome = getNPArray(trainOutcome)\n",
    "\n",
    "values_mean = np.sum(training_data_outcome)/len(training_data_outcome)\n",
    "\n",
    "ssres = np.sum((real_values - prediction_result)**2)\n",
    "sstot = np.sum((real_values - values_mean)**2)\n",
    "\n",
    "r_squared = 1 - ssres / sstot\n",
    "\n",
    "print(\"{0:.2f}\".format(r_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Testing your Model\n",
    "\n",
    "## Error Measures:\n",
    "\n",
    "### $RMSE$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16480.70\n"
     ]
    }
   ],
   "source": [
    "prediction_result = getNPArray(\n",
    "    predictionResult.get(prediction.prediction))\n",
    "real_values = getNPArray(testGroundTruth)\n",
    "\n",
    "rmse = math.sqrt(\n",
    "    np.sum((prediction_result-real_values)**2)/len(real_values))\n",
    "\n",
    "print(\"{0:.2f}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster assignments:\n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "1.000     \n",
      "2.000     \n",
      "0.000     \n",
      "2.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "2.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "0.000     \n",
      "2.000     \n",
      "0.000     \n",
      "2.000     \n",
      "2.000     \n",
      "2.000     \n",
      "2.000     \n",
      "0.000     \n",
      "2.000     \n",
      "2.000     \n",
      "2.000     \n",
      "2.000     \n",
      "2.000     \n",
      "2.000     \n",
      "0.000     \n",
      "0.000     \n",
      "2.000     \n",
      "2.000     \n",
      "2.000     \n",
      "2.000     \n",
      "0.000     \n",
      "2.000     \n",
      "0.000     \n",
      "2.000     \n",
      "0.000     \n",
      "2.000     \n",
      "2.000     \n",
      "0.000     \n",
      "0.000     \n",
      "2.000     \n",
      "2.000     \n",
      "2.000     \n",
      "2.000     \n",
      "2.000     \n",
      "0.000     \n",
      "2.000     \n",
      "2.000     \n",
      "2.000     \n",
      "2.000     \n",
      "0.000     \n",
      "2.000     \n",
      "2.000     \n",
      "2.000     \n",
      "0.000     \n",
      "2.000     \n",
      "2.000     \n",
      "2.000     \n",
      "0.000     \n",
      "2.000     \n",
      "2.000     \n",
      "0.000     \n",
      "\n",
      "First 4 dimensions of centroids:\n",
      "5.884     2.741     4.389     1.434     \n",
      "5.006     3.418     1.464     0.244     \n",
      "6.854     3.077     5.715     2.054     \n",
      "\n",
      "Goal function value:\n",
      "78.945    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 3\n",
    "n_iterations = 10\n",
    "\n",
    "clustering_data = np.genfromtxt('./iris.csv', delimiter=',')\n",
    "\n",
    "variables = np.delete(clustering_data, np.s_[4::1], 1)\n",
    "\n",
    "data_table = HomogenNumericTable(variables)\n",
    "\n",
    "initAlg = init.Batch_Float64RandomDense(n_clusters)\n",
    "\n",
    "initAlg.input.set(d, data_table)\n",
    "\n",
    "res = initAlg.compute()\n",
    "init_centroids = res.get(centroids)\n",
    "# Create an algorithm object for the K-Means algorithm\n",
    "\n",
    "algorithm = Batch_Float64LloydDense(n_clusters, n_iterations)\n",
    "\n",
    "algorithm.input.set(d,data_table)\n",
    "algorithm.input.set(inputCentroids, init_centroids)\n",
    "\n",
    "res = algorithm.compute()\n",
    "\n",
    "printNumericTable(res.get(kmeans.assignments), \"Cluster assignments:\")\n",
    "printNumericTable(res.get(kmeans.centroids), \"First 4 dimensions of centroids:\", 3, 4)\n",
    "printNumericTable(res.get(kmeans.goalFunction), \"Goal function value:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multiple inputs - splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations read on file 1: 215\n",
      "Observations read on file 2: 220\n"
     ]
    }
   ],
   "source": [
    "nBlocks = 2\n",
    "nFeatures = 4\n",
    "nOutcomes = 1\n",
    "trainDatasetFileNames = ['./housing-distributed-train1.csv', \n",
    "                         './housing-distributed-train2.csv']\n",
    "masterAlgorithm = training.Distributed(step2Master)\n",
    "for i in range(nBlocks):\n",
    "    trainDataSource = FileDataSource(trainDatasetFileNames[i], \n",
    "                               DataSourceIface.notAllocateNumericTable,\n",
    "                               DataSourceIface.doDictionaryFromContext)\n",
    "    trainData = HomogenNumericTable(nFeatures, 0, \n",
    "                                    NumericTableIface.notAllocate)\n",
    "    trainOutcome = HomogenNumericTable(nOutcomes, 0, \n",
    "                                       NumericTableIface.notAllocate)\n",
    "    mergedData = MergedNumericTable(trainOutcome, trainData)\n",
    "    nObservations = trainDataSource.loadDataBlock(mergedData)\n",
    "    print(\"Observations read on file {}: {}\".format((i+1), \n",
    "                                                    nObservations))\n",
    "    localAlgorithm = training.Distributed(step1Local)\n",
    "    localAlgorithm.input.set(training.data, trainData)    \n",
    "    localAlgorithm.input.set(training.dependentVariables, \n",
    "                             trainOutcome)\n",
    "    partialResult = localAlgorithm.compute()\n",
    "    masterAlgorithm.input.add(training.partialModels, \n",
    "                              partialResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multiple input - merging results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression coefficients:\n",
      "-6356.393 6.127     2760.738  16551.026 7322.687  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "masterAlgorithm.compute()\n",
    "\n",
    "trainingResult = masterAlgorithm.finalizeCompute()\n",
    "printNumericTable(trainingResult.get(training.model).getBeta(), \n",
    "                  \"Linear Regression coefficients:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Testing your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "testDatasetFileName = './housing-test.csv'\n",
    "\n",
    "testDataSource = FileDataSource(\n",
    "    testDatasetFileName, DataSourceIface.doAllocateNumericTable,\n",
    "    DataSourceIface.doDictionaryFromContext\n",
    ")\n",
    "\n",
    "testData = HomogenNumericTable(nFeatures, 0, \n",
    "                               NumericTableIface.notAllocate)\n",
    "testGroundTruth = HomogenNumericTable(nOutcomes, 0, \n",
    "                                      NumericTableIface.notAllocate)\n",
    "mergedData = MergedNumericTable(testGroundTruth,testData)\n",
    "\n",
    "testDataSource.loadDataBlock(mergedData)\n",
    "\n",
    "algorithm = prediction.Batch()\n",
    "\n",
    "algorithm.input.setTable(prediction.data, testData)\n",
    "algorithm.input.setModel(prediction.model, \n",
    "                         trainingResult.get(training.model))\n",
    "\n",
    "predictionResult = algorithm.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Testing your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression prediction results: (first 10 rows):\n",
      "77584.291 \n",
      "97463.689 \n",
      "54689.190 \n",
      "65962.833 \n",
      "75165.556 \n",
      "47366.503 \n",
      "55175.751 \n",
      "47366.503 \n",
      "62841.671 \n",
      "65407.807 \n",
      "\n",
      "Ground truth (first 10 rows):\n",
      "75000.000 \n",
      "132000.000\n",
      "60000.000 \n",
      "65000.000 \n",
      "69000.000 \n",
      "51900.000 \n",
      "57000.000 \n",
      "65000.000 \n",
      "79500.000 \n",
      "72500.000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "printNumericTable(predictionResult.get(prediction.prediction), \n",
    "          \"Linear Regression prediction results: (first 10 rows):\", 10)\n",
    "printNumericTable(testGroundTruth, \"Ground truth (first 10 rows):\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Any questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
